{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducción a Spark Streaming en Databricks\n",
    "\n",
    "## Objetivos\n",
    "\n",
    "- Comprender los conceptos básicos del procesamiento de datos en streaming.\n",
    "- Configurar un flujo de trabajo de streaming utilizando Databricks y Apache Spark.\n",
    "- Realizar transformaciones básicas sobre datos en tiempo real.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 1: Ingesta de Datos en Streaming\n",
    "\n",
    "### Paso 1: Definir las rutas de los archivos\n",
    "\n",
    "- **`file_path`:** Esta es la ruta donde se encuentran los datos JSON que vamos a procesar. Databricks proporciona estos datos en la carpeta `/databricks-datasets/structured-streaming/events`.\n",
    "- **`checkpoint_path`:** Spark necesita un lugar para guardar información del estado del streaming (checkpoints). Esto es necesario para garantizar que, si el proceso se interrumpe, pueda reanudarse sin perder información.\n",
    "\n",
    "#### Instrucciones:\n",
    "1. Define las variables `file_path` y `checkpoint_path` como se muestra a continuación:\n",
    "\n",
    "```python\n",
    "file_path = \"/databricks-datasets/structured-streaming/events\"\n",
    "checkpoint_path = \"/tmp/ss-tutorial/_checkpoint\"\n",
    "```\n",
    "\n",
    "### Paso 2: Leer los datos en streaming\n",
    "\n",
    "Usa el formato **`cloudFiles`** para leer los datos JSON en tiempo real. La opción **`cloudFiles.schemaLocation`** permite a Spark detectar y almacenar el esquema de los datos en la ubicación del checkpoint.\n",
    "\n",
    "#### Instrucciones:\n",
    "1. Crea un DataFrame de streaming utilizando spark.readStream.\n",
    "\n",
    "2. Visualiza los datos utilizando `display`.\n",
    "\n",
    "En este punto, deberías ver los datos en tiempo real conforme se procesan.\n",
    "\n",
    "---\n",
    "\n",
    "## Parte 3: Transformación de los Datos\n",
    "\n",
    "- Mantener todas las columnas originales.\n",
    "- Añadir una columna que indique la fuente del archivo de donde provienen los datos (\"_metadata.file_path\").\n",
    "- Incluir una marca de tiempo que muestre cuándo se procesó cada fila.\n",
    "- Visualiza los datos utilizando `display`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
