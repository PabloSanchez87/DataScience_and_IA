{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Notebook 2 - Lectura y Procesamiento de Datos en Streaming\n",
    "\n",
    "### Instrucciones\n",
    "\n",
    "1. **Crear un nuevo Notebook en Databricks** llamado `Procesamiento_CoinCap`.\n",
    "2. **Configurar Spark Streaming** para leer los datos guardados por el primer notebook.\n",
    "3. **Transformar los datos**.\n",
    "\n",
    "### Enunciado\n",
    "\n",
    "1. **Configura la lectura en streaming** de los archivos JSON desde la ruta `/tmp/coincap_stream/`.\n",
    "2. **Define el esquema** de los datos basándote en la estructura de la respuesta de la API de CoinCap.\n",
    "3. **Aplica transformaciones**(Opcional) revisa si puede ser interesante aplicar alguna transformación por ejemplo incluir el valor en €.\n",
    "4. **Agrega una marca de tiempo** para cada registro indicando cuándo fue procesado.\n",
    "5. **KPIs**: \n",
    "    1. **Detección de cambios bruscos** en los precios (por ejemplo, variaciones superiores al 5% en 10 minutos).\n",
    "    2. **(Opcional)** ¿se te ocurre alguno interesante?\n",
    "\n",
    "\n",
    "### Puntos Clave\n",
    "\n",
    "- Configura un `checkpoint` para mantener el estado del streaming.\n",
    "- Visualiza los datos con `display()` para verificar que la ingesta está funcionando correctamente.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
